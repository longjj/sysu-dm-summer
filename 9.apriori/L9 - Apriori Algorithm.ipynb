{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "We use \n",
    "* a single letter string to represent an **item**\n",
    "* a `frozenset` to represent an **itemset**\n",
    "* class `Transactions` to present the **transaction database** (a collection of **itemset**s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The `Transactions` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# helper function\n",
    "# we choose to use `frozenset` so that it is hashable (e.g., harder to remove duplicates); `set` is not\n",
    "def itemset(*list_of_items): # `splat` allow us to send in multiple arguments\n",
    "    return frozenset(sorted(list_of_items)) # there is no need to sort, but sorted set is better for debugging\n",
    "\n",
    "# print(set) does not display set items in sorted order, hence we need to do it ourselves\n",
    "# we overload the function depending on the type of the argument\n",
    "def to_str(obj):\n",
    "    if isinstance(obj, frozenset):\n",
    "        return '{{{}}}'.format(', '.join(sorted(obj)))\n",
    "    elif isinstance(obj, list):\n",
    "        strs = [to_str(fs) for fs in obj]\n",
    "        return '[ {} ]'.format(', '.join(strs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "frozenset({'A', 'B', 'D', 'X'})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = itemset('B', 'A', 'D', 'X')\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozenset({'B', 'A', 'D', 'X'})\n",
      "{A, B, D, X}\n"
     ]
    }
   ],
   "source": [
    "print(t)\n",
    "print(to_str(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[ {A, B, D, X}, {A, E} ]'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = itemset('A', 'E')\n",
    "list_of_itemsets = [t, t1]\n",
    "to_str(list_of_itemsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itemset('A', 'B') == itemset('B', 'A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{A, C, D}\n",
      "{B, C}\n",
      "{A, B, E}\n",
      "{B, E}\n",
      "{A, B, C, D, E}\n",
      "{D, E}\n",
      "supp({A, B}) = 2\n",
      "unique items are: ['A', 'B', 'C', 'D', 'E']\n",
      "minsup = 1, frequent items = [ {A}, {B}, {C}, {D}, {E} ]\n",
      "minsup = 2, frequent items = [ {A}, {B}, {C}, {D}, {E} ]\n",
      "minsup = 3, frequent items = [ {A}, {B}, {C}, {D}, {E} ]\n",
      "minsup = 4, frequent items = [ {B}, {E} ]\n",
      "minsup = 5, frequent items = [  ]\n",
      "minsup = 6, frequent items = [  ]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class transactions:\n",
    "    def __init__(self, filename):\n",
    "        trans_sets = []\n",
    "        with open(filename, 'r') as f:\n",
    "            for line in f:\n",
    "                fields = line.split() # format: a transaction per line, consisting of items \n",
    "                trans_sets.append(itemset(*fields))\n",
    "        self.trans_sets = trans_sets\n",
    "    \n",
    "    def get_tdb(self):\n",
    "        return self.trans_sets\n",
    "\n",
    "    def support(self, itemset):        \n",
    "        # naive counting. `itemset` must be a set\n",
    "        match_vector = [1 if itemset.issubset(trans) else 0 for trans in self.trans_sets]\n",
    "        return np.sum(match_vector)\n",
    "    \n",
    "    def get_items(self):\n",
    "        items = set()\n",
    "        for itemset in self.trans_sets:\n",
    "            items = items.union(itemset)\n",
    "        return sorted(items)\n",
    "    \n",
    "    def get_frequent_items(self, minsup):\n",
    "        return [itemset(item) for item in self.get_items() if self.support(itemset(item)) >= minsup]\n",
    "    \n",
    "    def len(self):\n",
    "        return len(self.trans_sets)\n",
    "    \n",
    "    def dump(self):\n",
    "        for trans in self.trans_sets:\n",
    "            print('{}'.format(to_str(trans)))\n",
    "    \n",
    "        \n",
    "db = transactions('asset/trans.txt')\n",
    "db.dump()\n",
    "\n",
    "my_itemset = itemset('B', 'A')\n",
    "print('supp({}) = {}'.format(to_str(my_itemset), db.support(my_itemset)))\n",
    "      \n",
    "print('unique items are: {}'.format(db.get_items()))\n",
    "for i in range(1, db.len()+1):\n",
    "    print('minsup = {}, frequent items = {}'.format(i, to_str(db.get_frequent_items(i))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Apriori Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def merge_itemsets(itemset1, itemset2):\n",
    "    merged = set(itemset1)\n",
    "    merged = merged.union(itemset2)\n",
    "    return frozenset(merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{A, B, C}\n",
      "{A, B, C, D}\n"
     ]
    }
   ],
   "source": [
    "itmset1 = itemset('A', 'B')\n",
    "itmset2 = itemset('A', 'C')\n",
    "itmset3 = itemset('A', 'D')\n",
    "itmset4 = itemset('B', 'C')\n",
    "\n",
    "print(to_str(merge_itemsets(itmset1, itmset2)))\n",
    "print(to_str(merge_itemsets(itmset3, itmset4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# debug == 0: print nothing\n",
    "# debug == 1: print input and output itemsets\n",
    "# debug == 2: print all details\n",
    "def gen_candidate_itemsets(freq_itemsets, debug = 1):\n",
    "    if len(freq_itemsets) == 0: return []\n",
    "    \n",
    "    # freq_itemsets is a set of itemset (which is nothing but Set)  \n",
    "    current_len = len(freq_itemsets[0])\n",
    "    if debug >= 1: print('.. Input  (L_k)   :\\t{}'.format(to_str(freq_itemsets)))\n",
    "    \n",
    "    # using set() to remove duplicates\n",
    "    merged_itemsets = set([merge_itemsets(set1, set2) \n",
    "                           for set1 in freq_itemsets for set2 in freq_itemsets \n",
    "                               if str(set1) < str(set2)])\n",
    "    if debug >= 2: print('..  .. Merged: {}'.format(to_str(merged_itemsets)))\n",
    "\n",
    "    candidates = []\n",
    "    for x in merged_itemsets:\n",
    "        if debug >=2: print('.. .. Checking {}'.format(x))\n",
    "        if len(x) == current_len + 1:\n",
    "            pruned = False\n",
    "            for elem in x:\n",
    "                sub_itemset = set(x) # need to make a copy\n",
    "                sub_itemset.remove(elem) # remove one item\n",
    "                if sub_itemset not in freq_itemsets:\n",
    "                    pruned = True\n",
    "                    break\n",
    "            if not pruned:\n",
    "                candidates.append(x)\n",
    "    if debug >= 1: print('.. Output (C_(k+1):\\t{}'.format(to_str(candidates)))\n",
    "    \n",
    "    return candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ {A, B}, {A, C}, {A, D}, {B, C} ]\n",
      ".. Input  (L_k)   :\t[ {A, B}, {A, C}, {A, D}, {B, C} ]\n",
      ".. Output (C_(k+1):\t[ {A, B, C} ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[frozenset({'A', 'B', 'C'})]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_itemsets = [itmset1, itmset2, itmset3, itmset4]\n",
    "print(to_str(my_itemsets))\n",
    "gen_candidate_itemsets(my_itemsets, debug = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def output(freq_itemsets):\n",
    "    for x in freq_itemsets:\n",
    "        print('{} => {}'.format(to_str(x), db.support(x)))\n",
    "\n",
    "def apriori(db, minsup):\n",
    "    last_frequent_itemsets = db.get_frequent_items(minsup)\n",
    "    output(last_frequent_itemsets)\n",
    "    count = 1\n",
    "    \n",
    "    # generate candidate itemsets \n",
    "    candidate_itemsets = gen_candidate_itemsets(last_frequent_itemsets)\n",
    "    while len(candidate_itemsets) > 0:\n",
    "        count += 1\n",
    "        print('\\n** Iteration {}'.format(count))\n",
    "        last_frequent_itemsets = [itemsets for itemsets in candidate_itemsets if db.support(itemsets) >= minsup]\n",
    "        output(last_frequent_itemsets)\n",
    "        candidate_itemsets = gen_candidate_itemsets(last_frequent_itemsets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{A} => 3\n",
      "{B} => 4\n",
      "{C} => 3\n",
      "{D} => 3\n",
      "{E} => 4\n",
      ".. Input  (L_k)   :\t[ {A}, {B}, {C}, {D}, {E} ]\n",
      ".. Output (C_(k+1):\t[ {B, C}, {B, D}, {A, C}, {A, D}, {C, D}, {C, E}, {B, E}, {A, E}, {D, E}, {A, B} ]\n",
      "\n",
      "** Iteration 2\n",
      "{B, C} => 2\n",
      "{A, C} => 2\n",
      "{A, D} => 2\n",
      "{C, D} => 2\n",
      "{B, E} => 3\n",
      "{A, E} => 2\n",
      "{D, E} => 2\n",
      "{A, B} => 2\n",
      ".. Input  (L_k)   :\t[ {B, C}, {A, C}, {A, D}, {C, D}, {B, E}, {A, E}, {D, E}, {A, B} ]\n",
      ".. Output (C_(k+1):\t[ {A, D, E}, {A, B, C}, {A, C, D}, {A, B, E} ]\n",
      "\n",
      "** Iteration 3\n",
      "{A, C, D} => 2\n",
      "{A, B, E} => 2\n",
      ".. Input  (L_k)   :\t[ {A, C, D}, {A, B, E} ]\n",
      ".. Output (C_(k+1):\t[  ]\n"
     ]
    }
   ],
   "source": [
    "# change the default `debug` value to 1 (or 2) to see more info\n",
    "apriori(db, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you turn on the debugging info, you can see that only `ABE` and `ACD` are identified as $C_3$. E.g., both `AB` and `AD` are in $L_2$, but since `BD` is not in $L_2$, `ABD` is not added to $C_3$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{A} => 3\n",
      "{B} => 4\n",
      "{C} => 3\n",
      "{D} => 3\n",
      "{E} => 4\n",
      ".. Input  (L_k)   :\t[ {A}, {B}, {C}, {D}, {E} ]\n",
      ".. Output (C_(k+1):\t[ {B, C}, {B, D}, {A, C}, {A, D}, {C, D}, {C, E}, {B, E}, {A, E}, {D, E}, {A, B} ]\n",
      "\n",
      "** Iteration 2\n",
      "{B, E} => 3\n",
      ".. Input  (L_k)   :\t[ {B, E} ]\n",
      ".. Output (C_(k+1):\t[  ]\n"
     ]
    }
   ],
   "source": [
    "apriori(db, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{B} => 4\n",
      "{E} => 4\n",
      ".. Input  (L_k)   :\t[ {B}, {E} ]\n",
      ".. Output (C_(k+1):\t[ {B, E} ]\n",
      "\n",
      "** Iteration 2\n"
     ]
    }
   ],
   "source": [
    "apriori(db, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "apriori(db, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
